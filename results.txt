Count CLF
{'estimator__learning_rate': 0.1,
 'estimator__max_depth': 7,
 'estimator__n_estimators': 100}
 
             precision    recall  f1-score   support

          0     0.8585    0.9482    0.9011      4321
          5     0.9756    0.9091    0.9412       220
          6     0.8361    0.5730    0.6800        89
         26     0.9667    0.9667    0.9667        30
         33     0.8929    0.7732    0.8287        97
        139     1.0000    0.7586    0.8627        29
        163     0.8611    0.8267    0.8435        75
        232     0.8545    0.5281    0.6528        89
        313     0.9211    0.5645    0.7000        62
        339     0.9583    0.6509    0.7753       530
        350     0.8478    0.8298    0.8387        47
        406     0.9667    0.7436    0.8406        39
        409     0.8519    0.8846    0.8679        78
        555     0.9231    0.7059    0.8000        34
        589     0.9000    0.8571    0.8780        63
        597     0.9375    1.0000    0.9677        15
        634     0.9211    0.9333    0.9272        75
        660     0.9602    0.8260    0.8881       730
        695     0.9806    0.9528    0.9665       106
        729     1.0000    0.9130    0.9545        23
        766     0.9394    0.6327    0.7561        49
        773     0.9851    0.9429    0.9635        70
        793     0.9545    0.8400    0.8936        75
        800     0.9915    0.9832    0.9874       477
        810     1.0000    0.8972    0.9458       253
        852     0.9143    0.7901    0.8477        81
        895     0.9799    0.9669    0.9733       151
        951     1.0000    0.9909    0.9954       110
        975     0.9429    0.9429    0.9429        35

avg / total     0.9027    0.8936    0.8929      8053

0.8276063752010527

TFIDF CLF
{'estimator__learning_rate': 0.1,
 'estimator__max_depth': 2,
 'estimator__n_estimators': 500}
             precision    recall  f1-score   support

          0     0.8501    0.9477    0.8963      4321
          5     0.9810    0.9364    0.9581       220
          6     0.8857    0.6966    0.7799        89
         26     0.9310    0.9000    0.9153        30
         33     0.8861    0.7216    0.7955        97
        139     1.0000    0.7931    0.8846        29
        163     0.8767    0.8533    0.8649        75
        232     0.8689    0.5955    0.7067        89
        313     0.9524    0.6452    0.7692        62
        339     0.9368    0.6434    0.7629       530
        350     0.8043    0.7872    0.7957        47
        406     0.9688    0.7949    0.8732        39
        409     0.8734    0.8846    0.8790        78
        555     0.9500    0.5588    0.7037        34
        589     0.8710    0.8571    0.8640        63
        597     0.9375    1.0000    0.9677        15
        634     0.9474    0.9600    0.9536        75
        660     0.9544    0.8315    0.8887       730
        695     0.9806    0.9528    0.9665       106
        729     1.0000    0.9130    0.9545        23
        766     0.9474    0.7347    0.8276        49
        773     1.0000    0.9286    0.9630        70
        793     0.9706    0.8800    0.9231        75
        800     0.9957    0.9727    0.9841       477
        810     0.9742    0.8972    0.9342       253
        852     0.9412    0.7901    0.8591        81
        895     0.9800    0.9735    0.9767       151
        951     1.0000    0.9909    0.9954       110
        975     1.0000    0.9714    0.9855        35

avg / total     0.8977    0.8964    0.8922      8053

0.8195642637812546

LDA 10 Topics XGBoost Validation
{'estimator__learning_rate': 0.1,
 'estimator__max_depth': 4,
 'estimator__n_estimators': 100}

             precision    recall  f1-score   support

          0     0.7607    0.9280    0.8361      4322
          5     0.8741    0.5656    0.6868       221
          6     0.5641    0.2472    0.3438        89
         26     0.7000    0.4828    0.5714        29
         33     0.8000    0.1237    0.2143        97
        139     0.5294    0.3000    0.3830        30
        163     0.8519    0.9079    0.8790        76
        232     0.0000    0.0000    0.0000        89
        313     0.7500    0.0492    0.0923        61
        339     1.0000    0.0038    0.0075       529
        350     0.8049    0.7021    0.7500        47
        406     1.0000    0.4359    0.6071        39
        409     0.7778    0.8077    0.7925        78
        555     1.0000    0.0588    0.1111        34
        589     0.8929    0.3906    0.5435        64
        597     0.9167    0.6875    0.7857        16
        634     0.8194    0.7867    0.8027        75
        660     0.8027    0.3292    0.4669       729
        695     0.9677    0.8491    0.9045       106
        729     1.0000    0.7917    0.8837        24
        766     0.0000    0.0000    0.0000        49
        773     0.9524    0.8571    0.9023        70
        793     0.6327    0.4133    0.5000        75
        800     0.8550    0.7296    0.7873       477
        810     0.8367    0.1614    0.2706       254
        852     0.6774    0.2561    0.3717        82
        895     0.1250    0.0066    0.0126       151
        951     0.9712    0.9266    0.9484       109
        975     0.9524    0.5714    0.7143        35

avg / total     0.7756    0.6763    0.6598      8057

0.6340251388482899

LDA 30 Topics XGBoost Validation
{'estimator__learning_rate': 0.1,
 'estimator__max_depth': 7,
 'estimator__n_estimators': 100}
 
              precision    recall  f1-score   support

          0     0.8146    0.9139    0.8614      4322
          5     0.9176    0.7059    0.7980       221
          6     0.6286    0.4944    0.5535        89
         26     0.7917    0.6552    0.7170        29
         33     0.7586    0.4536    0.5677        97
        139     0.7000    0.4667    0.5600        30
        163     0.8625    0.9079    0.8846        76
        232     0.6512    0.3146    0.4242        89
        313     0.8095    0.2787    0.4146        61
        339     0.6522    0.0567    0.1043       529
        350     0.8537    0.7447    0.7955        47
        406     0.9032    0.7179    0.8000        39
        409     0.7766    0.9359    0.8488        78
        555     0.7895    0.4412    0.5660        34
        589     0.8980    0.6875    0.7788        64
        597     1.0000    0.8750    0.9333        16
        634     0.9189    0.9067    0.9128        75
        660     0.8056    0.4719    0.5952       729
        695     0.9691    0.8868    0.9261       106
        729     1.0000    1.0000    1.0000        24
        766     0.6800    0.3469    0.4595        49
        773     0.9844    0.9000    0.9403        70
        793     0.8889    0.6400    0.7442        75
        800     0.9493    0.8239    0.8822       477
        810     0.9085    0.5866    0.7129       254
        852     0.7733    0.7073    0.7389        82
        895     0.6286    0.2914    0.3982       151
        951     1.0000    0.9541    0.9765       109
        975     0.9643    0.7714    0.8571        35

avg / total     0.8176    0.7463    0.7538      8057

0.6908798596901491

LDA 50 Topics XGBoost Validation
{'estimator__learning_rate': 0.1,
 'estimator__max_depth': 7,
 'estimator__n_estimators': 100}
 
              precision    recall  f1-score   support

          0     0.8272    0.9190    0.8707      4322
          5     0.9412    0.7964    0.8627       221
          6     0.6197    0.4944    0.5500        89
         26     0.8750    0.7241    0.7925        29
         33     0.7353    0.5155    0.6061        97
        139     0.7143    0.5000    0.5882        30
        163     0.9041    0.8684    0.8859        76
        232     0.5918    0.3258    0.4203        89
        313     0.8108    0.4918    0.6122        61
        339     0.5507    0.0718    0.1271       529
        350     0.8298    0.8298    0.8298        47
        406     0.8529    0.7436    0.7945        39
        409     0.8068    0.9103    0.8554        78
        555     0.8182    0.2647    0.4000        34
        589     0.8909    0.7656    0.8235        64
        597     1.0000    0.9375    0.9677        16
        634     0.9333    0.9333    0.9333        75
        660     0.8096    0.5075    0.6239       729
        695     0.9706    0.9340    0.9519       106
        729     1.0000    0.9167    0.9565        24
        766     0.6800    0.3469    0.4595        49
        773     0.9710    0.9571    0.9640        70
        793     0.8627    0.5867    0.6984        75
        800     0.9709    0.8386    0.8999       477
        810     0.9297    0.6772    0.7836       254
        852     0.8286    0.7073    0.7632        82
        895     0.7049    0.2848    0.4057       151
        951     1.0000    0.9633    0.9813       109
        975     0.9655    0.8000    0.8750        35

avg / total     0.8221    0.7631    0.7708      8057

0.7060800935399006

LDA 100 Topics XGBoost Validation
{'estimator__learning_rate': 0.1,
 'estimator__max_depth': 5,
 'estimator__n_estimators': 100}
 
          precision    recall  f1-score   support

          0     0.8227    0.9317    0.8738      4322
          5     0.9838    0.8235    0.8966       221
          6     0.7101    0.5506    0.6203        89
         26     0.8276    0.8276    0.8276        29
         33     0.8667    0.5361    0.6624        97
        139     0.7778    0.4667    0.5833        30
        163     0.8961    0.9079    0.9020        76
        232     0.6667    0.2921    0.4062        89
        313     0.7838    0.4754    0.5918        61
        339     0.6790    0.1040    0.1803       529
        350     0.7872    0.7872    0.7872        47
        406     0.8182    0.6923    0.7500        39
        409     0.8090    0.9231    0.8623        78
        555     0.6667    0.2941    0.4082        34
        589     0.8772    0.7812    0.8264        64
        597     0.9333    0.8750    0.9032        16
        634     0.9306    0.8933    0.9116        75
        660     0.8371    0.5569    0.6689       729
        695     0.9800    0.9245    0.9515       106
        729     1.0000    1.0000    1.0000        24
        766     0.7917    0.3878    0.5205        49
        773     0.9697    0.9143    0.9412        70
        793     0.8772    0.6667    0.7576        75
        800     0.9676    0.8763    0.9197       477
        810     0.9086    0.7047    0.7938       254
        852     0.8333    0.8537    0.8434        82
        895     0.7556    0.4503    0.5643       151
        951     1.0000    0.9725    0.9860       109
        975     0.9375    0.8571    0.8955        35

avg / total     0.8347    0.7864    0.7880      8057

0.7195264542531423

LDA 300 Topics XGBoost Validation
{'estimator__learning_rate': 0.1,
 'estimator__max_depth': 5,
 'estimator__n_estimators': 100}
 
              precision    recall  f1-score   support

          0     0.8236    0.9419    0.8788      4322
          5     0.9500    0.8597    0.9026       221
          6     0.6753    0.5843    0.6265        89
         26     0.8214    0.7931    0.8070        29
         33     0.8594    0.5670    0.6832        97
        139     0.7368    0.4667    0.5714        30
        163     0.8800    0.8684    0.8742        76
        232     0.7593    0.4607    0.5734        89
        313     0.8438    0.4426    0.5806        61
        339     0.7865    0.1323    0.2265       529
        350     0.8696    0.8511    0.8602        47
        406     0.8056    0.7436    0.7733        39
        409     0.8111    0.9359    0.8690        78
        555     0.8462    0.3235    0.4681        34
        589     0.8852    0.8438    0.8640        64
        597     1.0000    0.8750    0.9333        16
        634     0.9351    0.9600    0.9474        75
        660     0.8403    0.6063    0.7044       729
        695     0.9800    0.9245    0.9515       106
        729     1.0000    0.9167    0.9565        24
        766     0.8800    0.4490    0.5946        49
        773     0.9710    0.9571    0.9640        70
        793     0.8594    0.7333    0.7914        75
        800     0.9775    0.9099    0.9425       477
        810     0.9057    0.7559    0.8240       254
        852     0.8481    0.8171    0.8323        82
        895     0.6889    0.4106    0.5145       151
        951     1.0000    0.9541    0.9765       109
        975     0.9688    0.8857    0.9254        35

avg / total     0.8436    0.8065    0.8025      8057

0.7364805612394036
