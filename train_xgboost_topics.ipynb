{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, hamming_loss, zero_one_loss, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THEMES = [5, 6, 26, 33, 139, 163, 232, 313, 339, 350, 406, 409, 555, 589,\n",
    "          597, 634, 660, 695, 729, 766, 773, 793, 800, 810, 852, 895, 951, 975]\n",
    "TRAIN_DATA_PATH = '../train.csv'\n",
    "TEST_DATA_PATH = '../test.csv'\n",
    "VALIDATION_DATA_PATH = '../validation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def groupby_process(df):\n",
    "    new_df = df.sort_values(['process_id', 'page'])\n",
    "    new_df = new_df.groupby(\n",
    "                ['process_id', 'themes'],\n",
    "                group_keys=False\n",
    "            ).apply(lambda x: x.body.str.cat(sep=' ')).reset_index()\n",
    "    new_df = new_df.rename(index=str, columns={0: \"body\"})\n",
    "    return new_df\n",
    "\n",
    "def get_data(path, preds=None, key=None):\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.rename(columns={ 'pages': 'page'})\n",
    "    data = groupby_process(data)\n",
    "    data.themes = data.themes.apply(lambda x: literal_eval(x))\n",
    "    return data\n",
    "\n",
    "def transform_y(train_labels, test_labels):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(train_labels)\n",
    "\n",
    "    mlb_train = mlb.transform(train_labels)\n",
    "    mlb_test = mlb.transform(test_labels)\n",
    "\n",
    "    print(mlb.classes_)\n",
    "\n",
    "    return mlb_train, mlb_test, mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = get_data(TRAIN_DATA_PATH)\n",
    "test_data = get_data(TEST_DATA_PATH)\n",
    "validation_data = get_data(VALIDATION_DATA_PATH)\n",
    "\n",
    "train_data.themes = train_data.themes.apply(lambda x: list(set(sorted([i if i in THEMES else 0 for i in x]))))\n",
    "test_data.themes = test_data.themes.apply(lambda x: list(set(sorted([i if i in THEMES else 0 for i in x]))))\n",
    "validation_data.themes = validation_data.themes.apply(lambda x: list(set(sorted([i if i in THEMES else 0 for i in x]))))\n",
    "\n",
    "y_train, y_test, mlb = transform_y(train_data.themes, test_data.themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "xgboost = OneVsRestClassifier(XGBClassifier(\n",
    "                n_jobs=-1,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.1,\n",
    "                n_estimators=500,\n",
    "            ),\n",
    "            n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uni\n",
    "\n",
    "param_dist = {\"estimator__max_depth\": sp_randint(1, 8),\n",
    "              \"estimator__learning_rate\": [0.1, 0.3, 0.5],\n",
    "              \"estimator__n_estimators\": [30, 100, 300, 500, 1000]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield([x for x in sentence.split(\" \") if len(x) > 1])\n",
    "\n",
    "def texts_to_feats(texts, model, dictionary):\n",
    "    texts_words = sent_to_words(texts)\n",
    "    texts_corpus = [dictionary.doc2bow(text) for text in texts_words]\n",
    "    texts_topic_dist = [model.get_document_topics(text) for text in text_corpus]\n",
    "    return np.array([y[1] for y in dist.sort(key=lambda x: x[0])] for dist in texts_topic_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "import gensim\n",
    "\n",
    "model_opt = \"first\"\n",
    "\n",
    "model = gensim.models.ldamodel.LdaModel.load(\"models/lda_big_{}\".format(model_opt))\n",
    "dictionary = corpora.Dictionary.load(\"dicts/big_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = texts_to_feats(train_data.body, model, dictionary)\n",
    "X_valid = texts_to_feats(validation_data.body, model, dictionary)\n",
    "X_test = texts_to_feats(test_data.body, model, dictionary)\n",
    "y_valid = mlb.transform(validation_data.themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('X_train: {}, \\n\\ty_train: {}'.format(X_train.shape, y_train.shape))\n",
    "print('X_test: {}, \\n\\ty_test: {}'.format(X_test.shape, y_test.shape))\n",
    "print('Classes: ', mlb.classes_)\n",
    "print('We\\'re classifying {} themes!'.format(y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(xgboost, param_distributions=param_dist,\n",
    "                                   n_iter=20, n_jobs=1, iid=False, refit=False,\n",
    "                                   verbose=2, random_state=42)\n",
    "random_search.fit(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = random_search.best_params_; best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost = random_search.estimator.set_params(**best_params); xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names=[str(x) for x in mlb.classes_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_test = xgboost.predict(X_test)\n",
    "print(classification_report(y_test, preds_test, target_names=target_names, digits=4))\n",
    "print(accuracy_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(xgboost, './models/lda_xgboost.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37264bitmlconda45db6e2d0d274db0bab09cf55bdc23f9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
